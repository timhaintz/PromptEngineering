"""
Azure OAuth Token Caching Usage Examples

This script demonstrates how to use the secure OAuth token caching implementation
with Azure OpenAI models following Azure security best practices.

Features:
- Secure token caching using Azure Identity TokenCachePersistenceOptions
- OS-level encrypted credential storage (Windows Credential Manager, macOS Keychain, Linux Secret Service)
- Automatic token refresh and reuse across sessions
- Unified interface for Azure OpenAI, Direct API, and Azure AI Foundry models
"""

import logging
from azure_models import (
    create_azure_openai_client, 
    create_unified_client,
    get_streaming_models,
    supports_streaming
)

# Configure logging to see authentication and caching activity
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def example_azure_openai_with_caching():
    """Example: Using Azure OpenAI with secure token caching."""
    print("ğŸ” Example 1: Azure OpenAI with Secure Token Caching")
    print("-" * 60)
    
    try:
        # Create Azure OpenAI client with secure token caching
        # Tokens are automatically cached in encrypted OS credential stores
        client = create_azure_openai_client("gpt-4.1")
        
        print("âœ… Azure OpenAI client created with secure token caching")
        print("ğŸ”’ Features enabled:")
        print("   â€¢ Encrypted token storage in OS credential manager")
        print("   â€¢ Automatic token refresh when expired")
        print("   â€¢ Secure application-level cache isolation")
        
        # Example chat completion
        response = client.chat.completions.create(
            model="gpt-4",  # This will use the deployment name from config
            messages=[{"role": "user", "content": "Hello, Azure!"}],
            max_tokens=50
        )
        
        print(f"ğŸ“ Response: {response.choices[0].message.content}")
        
    except Exception as e:
        print(f"âŒ Error: {e}")

def example_streaming_with_caching():
    """Example: Using streaming with cached authentication."""
    print("\nğŸŒŠ Example 2: Streaming with Cached Authentication") 
    print("-" * 60)
    
    try:
        # Get models that support streaming
        streaming_models = get_streaming_models()
        print(f"ğŸ“¡ Available streaming models: {list(streaming_models.keys())}")
        
        # Use a streaming model with cached authentication
        model_name = "gpt-4.1"
        if supports_streaming(model_name):
            client = create_azure_openai_client(model_name)
            
            print(f"âœ… Using {model_name} with streaming and cached auth")
            
            # Example streaming chat completion
            stream = client.chat.completions.create(
                model="gpt-4",
                messages=[{"role": "user", "content": "Count to 5 slowly"}],
                max_tokens=100,
                stream=True  # Enable streaming
            )
            
            print("ğŸŒŠ Streaming response: ", end="")
            for chunk in stream:
                if chunk.choices[0].delta.content:
                    print(chunk.choices[0].delta.content, end="", flush=True)
            print("\n")
            
        else:
            print(f"âš ï¸ Model {model_name} does not support streaming")
            
    except Exception as e:
        print(f"âŒ Streaming error: {e}")

def example_unified_client_with_caching():
    """Example: Using UnifiedChatClient with cached authentication."""
    print("\nğŸ”„ Example 3: Unified Client with Cached Authentication")
    print("-" * 60)
    
    try:
        # Create unified client that works with all model types
        unified_client = create_unified_client("gpt-4.1")
        
        print("âœ… Unified client created with cached authentication")
        print("ğŸ¯ Benefits:")
        print("   â€¢ Works with Azure OpenAI, Direct API, and Azure AI Foundry")
        print("   â€¢ Automatic credential caching across all model types")
        print("   â€¢ Consistent interface regardless of backend")
        
        # Check streaming support
        if unified_client.supports_streaming_feature():
            print("ğŸ“¡ Streaming support: Available")
        else:
            print("ğŸ“¡ Streaming support: Not available for this model")
            
        # Example usage (would work with any model type)
        print("ğŸš€ Ready for chat completions with secure, cached authentication")
        
    except Exception as e:
        print(f"âŒ Unified client error: {e}")

def example_multiple_sessions():
    """Example: Demonstrating token reuse across multiple sessions."""
    print("\nğŸ”„ Example 4: Token Reuse Across Multiple Sessions")
    print("-" * 60)
    
    try:
        print("Session 1: First authentication (may require browser)")
        client1 = create_azure_openai_client("gpt-4.1")
        print("âœ… Session 1 authenticated successfully")
        
        print("\nSession 2: Using cached token (should be instant)")
        client2 = create_azure_openai_client("gpt-4.1-nano") 
        print("âœ… Session 2 authenticated successfully (used cached token)")
        
        print("\nSession 3: Another model with same cached credentials")
        client3 = create_azure_openai_client("gpt-3.5-turbo")
        print("âœ… Session 3 authenticated successfully (used cached token)")
        
        print("\nğŸ¯ All three sessions used the same cached OAuth token!")
        print("ğŸ’¾ Token securely stored in:")
        print("   â€¢ Windows: Windows Credential Manager")
        print("   â€¢ macOS: Keychain")
        print("   â€¢ Linux: Secret Service API")
        
    except Exception as e:
        print(f"âŒ Multi-session error: {e}")

def main():
    """Run all OAuth caching examples."""
    print("ğŸ” Azure OAuth Token Caching Examples")
    print("=" * 70)
    print("Demonstrating secure token caching with Azure Identity library")
    print("=" * 70)
    
    # Run all examples
    example_azure_openai_with_caching()
    example_streaming_with_caching() 
    example_unified_client_with_caching()
    example_multiple_sessions()
    
    print("\n" + "=" * 70)
    print("ğŸ‰ All OAuth Caching Examples Complete!")
    print("\nğŸ”’ Security Summary:")
    print("â€¢ Tokens encrypted at rest using OS credential stores")
    print("â€¢ Automatic token refresh prevents expired credential errors")
    print("â€¢ Application-specific caching prevents token sharing")
    print("â€¢ No credentials stored in plain text or environment variables")
    print("â€¢ Fallback to in-memory cache if OS encryption unavailable")

if __name__ == "__main__":
    main()
